{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96374c1a-fcba-46a1-af9e-33d34d8560c5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Feature Engineering\n",
    "\n",
    "For some definitions, handling outliers and missing values, scaling, and encoding may be considered feature engineering. Here we'll draw a distinction between data preparation, data preprocessing, and feature engineering.\n",
    "\n",
    "- **data preparation**: the basic data cleaning necessary to get our data ready for exploration/analysis, e.g. correcting data types, fixing typos\n",
    "- **data preprocessing**: further data transformation done for the sake of modeling, as oppsoed to exploration/analysis, e.g. scaling, imputing, encoding\n",
    "- **feature engineering**: adding, combining, or removing features; usually with the help of domain knowledge\n",
    "\n",
    "Feature engineering can happen as part of data exploration or modeling, and engineered featured are also commonly explored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0129d56",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Some examples of feature engineering by this definition:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10038b9a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- domain-based conversion (example: farenheit to celsius, BMI calculation, log transformation)\n",
    "- domain based cutoffs (example: age >= 18 = is_adult; also dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd20c31",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- add / subtract (example: zillow dataset: beds + baths = room_count; total_sqft - 200 * bedrooms - 40 * bathrooms = living_area)\n",
    "- combine as booleans as a count (example: telco_churn: streaming + backups + ...  = service_count)\n",
    "- multiply / divide (example: tips dataset: total_bill / size = price_per_person)\n",
    "- ratios (example: tips dataset: tip / total_bill = tip percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641f264d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Simplify!\n",
    "\n",
    "- categorical with many unique values to top 3 + \"Other\"\n",
    "- categorical to boolean: pool count -> has pool\n",
    "- continous -> categorical via binning (aka quantization or discretization) (example: income -> high, medium, low earner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4104eb-91b5-4168-b53f-2a11597bfacb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "In this lesson we'll cover some *automated* **feature selection** methods, that is, methods for determining which features are the most important.\n",
    "\n",
    "- SelectKBest\n",
    "- Recursive Feature Elimination\n",
    "- Sequential Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed3a33a-2ca3-4625-94fd-def89bb5b497",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7018acce-d54f-4f9c-b9b8-ee2658d22d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, RFE, f_regression, SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a1679dd-51ed-4bf0-8871-7cb24761f270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_grades():\n",
    "    '''\n",
    "    Read student_grades csv file into a pandas DataFrame,\n",
    "    drop student_id column, replace whitespaces with NaN values,\n",
    "    drop any rows with Null values, convert all columns to int64,\n",
    "    return cleaned student grades DataFrame.\n",
    "    '''\n",
    "    # Acquire data from csv file.\n",
    "    df = pd.read_csv('student_grades.csv')\n",
    "    # Replace white space values with NaN values.\n",
    "    df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "    # Drop all rows with NaN values.\n",
    "    df = df.dropna()\n",
    "    # Convert all columns to int64 data types.\n",
    "    df = df.astype('int64')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e935049-00a7-42f2-91a4-375b07abacd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c566eaaa-ceb7-4cb6-8dbb-9c7200785367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95b821d-619b-4e94-8afd-0d9512c05411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59534ad5-8a6b-438f-b294-079988191ad2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>exam1</th>\n",
       "      <th>exam2</th>\n",
       "      <th>exam3</th>\n",
       "      <th>final_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>93</td>\n",
       "      <td>96</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "      <td>83</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "      <td>86</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>93</td>\n",
       "      <td>90</td>\n",
       "      <td>96</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>101</td>\n",
       "      <td>62</td>\n",
       "      <td>70</td>\n",
       "      <td>79</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>102</td>\n",
       "      <td>58</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>103</td>\n",
       "      <td>57</td>\n",
       "      <td>65</td>\n",
       "      <td>75</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>104</td>\n",
       "      <td>70</td>\n",
       "      <td>75</td>\n",
       "      <td>78</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id  exam1  exam2  exam3  final_grade\n",
       "0             1    100     90     95           96\n",
       "1             2     98     93     96           95\n",
       "2             3     85     83     87           87\n",
       "3             4     83     80     86           85\n",
       "4             5     93     90     96           97\n",
       "..          ...    ...    ...    ...          ...\n",
       "99          100     70     65     78           77\n",
       "100         101     62     70     79           70\n",
       "101         102     58     65     70           68\n",
       "102         103     57     65     75           65\n",
       "103         104     70     75     78           72\n",
       "\n",
       "[102 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = wrangle_grades()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e2b96c1-de4a-44d8-85ff-78b0f0c59c22",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'split_continuous' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f5/r0cvcy8d6bl6nqmwjp01nhjh0000gn/T/ipykernel_6042/3381815523.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# train, validate = train_test_split(train_validate)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_continuous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'split_continuous' is not defined"
     ]
    }
   ],
   "source": [
    "# train_validate, test = train_test_split(df)\n",
    "# train, validate = train_test_split(train_validate)\n",
    "\n",
    "train, validate, test = split_continuous(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc4ebee-12bc-432e-9631-e6c8adb10021",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Select K Best\n",
    "\n",
    "- looks at each feature in isolation against the target based on correlation\n",
    "- fastest of all approaches covered in this lesson\n",
    "- doesn't consider feature interactions\n",
    "- After fitting: `.scores_`, `.pvalues_`, `.get_support()`, and `.transform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e45b90-79ff-46e9-8d34-4b29fcd75e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the thing\n",
    "# fit the thing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dcf0dc-fc42-42fb-b1ab-e5dde8f186c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical f-value:\n",
    "#p value: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a07efc0-17e9-4b79-ba03-058c08fbcbcd",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# get-support() will output a boolean mask to tell me which features were selected\n",
    "# we can apply this mask to the columns in our original dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a1ad33-e05c-4748-8069-29b5355fa472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kbest transform will convert our information to the selected\n",
    "# feature subspace\n",
    "# ****buuuuuut, its just a numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18824290-e7ff-4213-84d1-8969f63e9aa2",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13a5069f-d6d6-49c4-aa81-76fdb806198b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RFE\n",
    "\n",
    "- Recursive Feature Elimination\n",
    "- Progressively eliminate features based on importance to the model\n",
    "- Requires a model with either a `.coef_` or `.feature_importances_` property\n",
    "- After fitting: `.ranking_`, `.get_support()`, and `.transform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5de219-03ba-4945-8fb1-fc4060f36502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e8d6e09-dab8-47d1-b7f4-8afca62d9d8c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sequential Feature Selector\n",
    "\n",
    "- progressively adds features based on cross validated model performance\n",
    "- forwards: start with 0, add the best additional feature until you have the desired number\n",
    "- backwards: start with all features, remove the worst performing until you have the desired number\n",
    "- After fitting: `.support_`, `.transform`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59d1a9a-9fa4-4c08-9680-c40300dcb5b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "- Simpler models handle change + variability better\n",
    "- Use RFE to narrow down your features and find the best ones, if your dataset is large (> 1GB; `df.info()`) use select k best instead\n",
    "- Remember: feature engineering is much more than feature selection!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "rise": {
   "enable_chalkboard": true,
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
